# LLM Post-Training Lab

A comprehensive repository for experimenting with different Large Language Model (LLM) post-training techniques, including Supervised Fine-Tuning (SFT), Direct Preference Optimization (DPO), and Reinforcement Learning (RL).

## Features

- **SFT (Supervised Fine-Tuning)**: Supervised training with high-quality data
- **DPO (Direct Preference Optimization)**: Direct preference optimization without reward models
- **RL (Reinforcement Learning)**: Reinforcement learning training using PPO and reward models

## Project Structure

```
llm-posttraining-lab/
â”œâ”€â”€ src/                    # Main source code
â”‚   â”œâ”€â”€ sft/               # SFT implementation
â”‚   â”œâ”€â”€ dpo/               # DPO implementation
â”‚   â””â”€â”€ rl/                # RL implementation
â”œâ”€â”€ examples/              # Executable examples
â”œâ”€â”€ data/                  # Training data
â”œâ”€â”€ configs/               # Configuration files
â””â”€â”€ scripts/               # Training scripts
```

## ðŸ“„ License

This project is licensed under the MIT License
